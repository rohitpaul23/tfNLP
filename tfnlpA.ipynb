{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "f_Uk-CAh6hNd",
        "d8FXPty-8bFA"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Text Classification BBC News Archive\n",
        "\n",
        "Understanding language Processing and constructing a model to classify BBC New Archive for different sections\n",
        "\n",
        "Outline:\n",
        "1. Tokenizer Basics\n",
        "2. Generating Sequence\n",
        "3. Explore BBC News Archive\n",
        "  * Removing Stopwords\n",
        "  * Reading Raw Data\n",
        "  * Training Validation split\n",
        "  * Tokenizing\n",
        "  * Training the model\n",
        "  * Visualizing 3D Vectofrs"
      ],
      "metadata": {
        "id": "jnS8aQgHmILz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenizer Basics\n",
        "In most NLP tasks, the initial step in preparing our data is to extract a vocabulary of words from our corpus (i.e. input texts). We will need to define how to represent the texts into numerical representations which can be used to train a neural network. These representations are called tokens and Tensorflow and Keras makes it easy to generate these using its APIs.\n",
        "Generating the vocabulary\n"
      ],
      "metadata": {
        "id": "f_Uk-CAh6hNd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJhZWBA76HP7",
        "outputId": "37bf1afe-d766-4444-eddd-e99d5c76aa6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'i': 1, 'love': 2, 'my': 3, 'dog': 4, 'cat': 5}\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "# Define input sentences\n",
        "sentences = [\n",
        "    'i love my dog',\n",
        "    'I, love my cat'\n",
        "    ]\n",
        "\n",
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer(num_words = 100)\n",
        "\n",
        "# Generate indices for each word in the corpus\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Get the indices and print it\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The num_words parameter used in the initializer specifies the maximum number of words minus one (based on frequency) to keep when generating sequences. The important thing to note is it does not affect how the word_index dictionary is generated. We can try passing 1 instead of 100 as shown on the next cell and you will arrive at the same word_index.\n",
        "\n",
        "Also notice that by default, all punctuation is ignored and words are converted to lower case. We can override these behaviors by modifying the filters and lower arguments of the Tokenizer class as described here.\n",
        "\n"
      ],
      "metadata": {
        "id": "idF_LzeG8Dbv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input sentences\n",
        "sentences = [\n",
        "    'i love my dog',\n",
        "    'I, love my cat',\n",
        "    'You love my dog!'\n",
        "]\n",
        "\n",
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer(num_words = 1)\n",
        "\n",
        "# Generate indices for each word in the corpus\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Get the indices and print it\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)# Define input sentences\n",
        "sentences = [\n",
        "    'i love my dog',\n",
        "    'I, love my cat',\n",
        "    'You love my dog!'\n",
        "]\n",
        "\n",
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer(num_words = 1)\n",
        "\n",
        "# Generate indices for each word in the corpus\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Get the indices and print it\n",
        "word_index = tokenizer.word_index\n",
        "print(word_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mjXcbmUm8bxD",
        "outputId": "f67027f6-8204-4191-e290-3945aea57140"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6}\n",
            "{'love': 1, 'my': 2, 'i': 3, 'dog': 4, 'cat': 5, 'you': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Generating Sequences and Padding\n",
        "Here, we will look at converting our input sentences into a sequence of tokens. We need to prepare text data with uniform size before feeding it to our model. \n",
        "\n",
        "Text to Sequences\n",
        "We saw how to generate a word_index dictionary to generate tokens for each word in our corpus. We can use the result to convert each of the input sentences into a sequence of tokens. That is done using the texts_to_sequences() method as shown below."
      ],
      "metadata": {
        "id": "d8FXPty-8bFA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "# Define your input texts\n",
        "sentences = [\n",
        "    'I love my dog',\n",
        "    'I love my cat',\n",
        "    'You love my dog!',\n",
        "    'Do you think my dog is amazing?'\n",
        "]\n",
        "\n",
        "# Initialize the Tokenizer class\n",
        "tokenizer = Tokenizer(num_words = 100, oov_token=\"<OOV>\")\n",
        "\n",
        "# Tokenize the input sentences\n",
        "tokenizer.fit_on_texts(sentences)\n",
        "\n",
        "# Get the word index dictionary\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "# Generate list of token sequences\n",
        "sequences = tokenizer.texts_to_sequences(sentences)\n",
        "\n",
        "# Print the result\n",
        "print(\"\\nWord Index = \" , word_index)\n",
        "print(\"\\nSequences = \" , sequences)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dNzUylz_-SD0",
        "outputId": "c2e46fa0-82c3-4d2f-adba-18084d4b05c2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Index =  {'<OOV>': 1, 'my': 2, 'love': 3, 'dog': 4, 'i': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11}\n",
            "\n",
            "Sequences =  [[5, 3, 2, 4], [5, 3, 2, 7], [6, 3, 2, 4], [8, 6, 9, 2, 4, 10, 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Padding\n",
        "\n",
        "We will usually need to pad the sequences into a uniform length because that is what our model expects. We can use the pad_sequences for that. By default, it will pad according to the length of the longest sequence. We can override this with the maxlen argument to define a specific length. \n"
      ],
      "metadata": {
        "id": "HFn8GVgh-mCQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Pad the sequences to a uniform length\n",
        "padded = pad_sequences(sequences, maxlen=5)\n",
        "\n",
        "# Print the result\n",
        "print(\"\\nPadded Sequences:\")\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rwg3fErD-jGv",
        "outputId": "cd8f4b16-f807-44e2-da57-7532e6d4e8a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Padded Sequences:\n",
            "[[ 0  5  3  2  4]\n",
            " [ 0  5  3  2  7]\n",
            " [ 0  6  3  2  4]\n",
            " [ 9  2  4 10 11]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Out-of-vocabulary tokens\n",
        "\n",
        "Notice that we defined an oov_token when the Tokenizer was initialized earlier. This will be used when we have input words that are not found in the word_index dictionary. For example, we may decide to collect more text after our initial training and decide to not re-generate the word_index.  Notice that the token 1 is inserted for words that are not found in the dictionary."
      ],
      "metadata": {
        "id": "FgsK2_Ut-9As"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Try with words that the tokenizer wasn't fit to\n",
        "test_data = [\n",
        "    'i really love my dog',\n",
        "    'my dog loves my manatee'\n",
        "]\n",
        "\n",
        "# Generate the sequences\n",
        "test_seq = tokenizer.texts_to_sequences(test_data)\n",
        "\n",
        "# Print the word index dictionary\n",
        "print(\"\\nWord Index = \" , word_index)\n",
        "\n",
        "# Print the sequences with OOV\n",
        "print(\"\\nTest Sequence = \", test_seq)\n",
        "\n",
        "# Print the padded result\n",
        "padded = pad_sequences(test_seq, maxlen=10)\n",
        "print(\"\\nPadded Test Sequence: \")\n",
        "print(padded)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gl7oxG88Aaxl",
        "outputId": "a14deb0c-eb29-480f-93aa-0375026313c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Word Index =  {'<OOV>': 1, 'my': 2, 'love': 3, 'dog': 4, 'i': 5, 'you': 6, 'cat': 7, 'do': 8, 'think': 9, 'is': 10, 'amazing': 11}\n",
            "\n",
            "Test Sequence =  [[5, 1, 3, 2, 4], [2, 4, 1, 2, 1]]\n",
            "\n",
            "Padded Test Sequence: \n",
            "[[0 0 0 0 0 5 1 3 2 4]\n",
            " [0 0 0 0 0 2 4 1 2 1]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Explore the BBC News archive\n",
        "\n",
        "Here, we will be working with a variation of the BBC News Classification Dataset, which contains 2225 examples of news articles with their respective categories (labels)"
      ],
      "metadata": {
        "id": "AyjifbtIC3gB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "ehs42WwdC_eU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(\"./BBC News Train.csv\", 'r') as csvfile:\n",
        "    print(f\"First line (header) looks like this:\\n\\n{csvfile.readline()}\")\n",
        "    print(f\"Each data point looks like this:\\n\\n{csvfile.readline()}\")     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEganTHnDGyP",
        "outputId": "03a43aa1-4739-4aec-964f-8fcc8a66dd58"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First line (header) looks like this:\n",
            "\n",
            "ArticleId,Text,Category\n",
            "\n",
            "Each data point looks like this:\n",
            "\n",
            "1833,worldcom ex-boss launches defence lawyers defending former worldcom chief bernie ebbers against a battery of fraud charges have called a company whistleblower as their first witness.  cynthia cooper  worldcom s ex-head of internal accounting  alerted directors to irregular accounting practices at the us telecoms giant in 2002. her warnings led to the collapse of the firm following the discovery of an $11bn (£5.7bn) accounting fraud. mr ebbers has pleaded not guilty to charges of fraud and conspiracy.  prosecution lawyers have argued that mr ebbers orchestrated a series of accounting tricks at worldcom  ordering employees to hide expenses and inflate revenues to meet wall street earnings estimates. but ms cooper  who now runs her own consulting business  told a jury in new york on wednesday that external auditors arthur andersen had approved worldcom s accounting in early 2001 and 2002. she said andersen had given a  green light  to the procedures and practices used by worldcom. mr ebber s lawyers have said he was unaware of the fraud  arguing that auditors did not alert him to any problems.  ms cooper also said that during shareholder meetings mr ebbers often passed over technical questions to the company s finance chief  giving only  brief  answers himself. the prosecution s star witness  former worldcom financial chief scott sullivan  has said that mr ebbers ordered accounting adjustments at the firm  telling him to  hit our books . however  ms cooper said mr sullivan had not mentioned  anything uncomfortable  about worldcom s accounting during a 2001 audit committee meeting. mr ebbers could face a jail sentence of 85 years if convicted of all the charges he is facing. worldcom emerged from bankruptcy protection in 2004  and is now known as mci. last week  mci agreed to a buyout by verizon communications in a deal valued at $6.75bn.,business\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "NUM_WORDS = 1000\n",
        "EMBEDDING_DIM = 16\n",
        "MAXLEN = 120\n",
        "PADDING = 'post'\n",
        "OOV_TOKEN = \"<OOV>\"\n",
        "TRAINING_SPLIT = .8"
      ],
      "metadata": {
        "id": "R8PHPj6hCYkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Removing Stopwords\n",
        "\n",
        "One important step when working with text data is to remove the stopwords from it. These are the most common words in the language and they rarely provide useful information for the classification process.\n"
      ],
      "metadata": {
        "id": "bBsMntp8Gfo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_stopwords(sentence):\n",
        "    \"\"\"\n",
        "    Removes a list of stopwords\n",
        "    \n",
        "    Args:\n",
        "        sentence (string): sentence to remove the stopwords from\n",
        "    \n",
        "    Returns:\n",
        "        sentence (string): lowercase sentence without the stopwords\n",
        "    \"\"\"\n",
        "    # List of stopwords\n",
        "    stopwords = [\"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
        "    \n",
        "    # Sentence converted to lowercase-only\n",
        "    sentence = sentence.lower()\n",
        "    newSentence=[]\n",
        "\n",
        "    for word in sentence.split(' '):\n",
        "      if word in stopwords:\n",
        "        continue\n",
        "      else:\n",
        "        newSentence.append(word)\n",
        "\n",
        "    return ' '.join(newSentence)"
      ],
      "metadata": {
        "id": "dAQRrJKvHB6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_stopwords(\"I am about to go to the store and get any snack\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "OZM4mVtIHsmv",
        "outputId": "232d528f-04d0-445c-d805-1586b8349df5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'go store get snack'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Reading the raw data\n",
        "Now you need to read the data from the csv file. To do so, we have parse_data_from_file function.\n",
        "\n",
        "A couple of things to note:\n",
        "\n",
        "* We should omit the first line as it contains the headers and not data points.\n",
        "* There is no need to save the data points as numpy arrays, regular lists is fine.\n",
        "* To read from csv files use csv.reader by passing the appropriate arguments.\n",
        "* csv.reader returns an iterable that returns each row in every iteration. So the label can be accessed via row[0] and the text via row[1].\n",
        "* Use the remove_stopwords function in each sentence."
      ],
      "metadata": {
        "id": "zTcAHlIXICtq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def parse_data_from_file(filename):\n",
        "    \"\"\"\n",
        "    Extracts sentences and labels from a CSV file\n",
        "    \n",
        "    Args:\n",
        "        filename (string): path to the CSV file\n",
        "    \n",
        "    Returns:\n",
        "        sentences, labels (list of string, list of string): tuple containing lists of sentences and labels\n",
        "    \"\"\"\n",
        "    sentences = []\n",
        "    labels = []\n",
        "    with open(filename, 'r') as csvfile:\n",
        "        \n",
        "        reader = csv.reader(csvfile, delimiter=',')\n",
        "        tag = 0\n",
        "        for line in reader:\n",
        "          if tag:\n",
        "            sentences.append(remove_stopwords(line[1]))\n",
        "            labels.append(line[2])\n",
        "          else:\n",
        "            tag=1\n",
        "\n",
        "    return sentences, labels"
      ],
      "metadata": {
        "id": "k1khj-gQIZHc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentences, labels = parse_data_from_file(\"./BBC News Train.csv\")\n",
        "\n",
        "print(\"ORIGINAL DATASET:\\n\")\n",
        "print(f\"There are {len(sentences)} sentences in the dataset.\\n\")\n",
        "print(f\"First sentence has {len(sentences[0].split())} words (after removing stopwords).\\n\")\n",
        "print(f\"There are {len(labels)} labels in the dataset.\\n\")\n",
        "print(f\"The first 5 labels are {labels[:5]}\\n\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZYrbdYNlJWhy",
        "outputId": "91483f01-3173-40dd-ab27-e5b140887167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ORIGINAL DATASET:\n",
            "\n",
            "There are 1490 sentences in the dataset.\n",
            "\n",
            "First sentence has 203 words (after removing stopwords).\n",
            "\n",
            "There are 1490 labels in the dataset.\n",
            "\n",
            "The first 5 labels are ['business', 'business', 'business', 'tech', 'business']\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Training - Validation Split\n",
        "Now we will code the train_val_split() function. Given the training split size, this function will split the full lists of sentences and labels into training and validation sentences and labels.\n",
        "\n"
      ],
      "metadata": {
        "id": "B5pYAu_TCrSp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val_split(sentences, labels, training_split):\n",
        "    \"\"\"\n",
        "    Splits the dataset into training and validation sets\n",
        "    \n",
        "    Args:\n",
        "        sentences (list of string): lower-cased sentences without stopwords\n",
        "        labels (list of string): list of labels\n",
        "        training split (float): proportion of the dataset to convert to include in the train set\n",
        "    \n",
        "    Returns:\n",
        "        train_sentences, validation_sentences, train_labels, validation_labels - lists containing the data splits\n",
        "    \"\"\"\n",
        "    \n",
        "    \n",
        "    # Compute the number of sentences that will be used for training (should be an integer)\n",
        "    train_size = int(len(sentences)*training_split)\n",
        "\n",
        "    # Split the sentences and labels into train/validation splits\n",
        "    train_sentences = sentences[:train_size]\n",
        "    train_labels = labels[:train_size]\n",
        "\n",
        "    validation_sentences = sentences[train_size:]\n",
        "    validation_labels = labels[train_size:]\n",
        "    \n",
        "    return train_sentences, validation_sentences, train_labels, validation_labels\n"
      ],
      "metadata": {
        "id": "ZvkmyqAeCvqf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences, val_sentences, train_labels, val_labels = train_val_split(sentences, labels, TRAINING_SPLIT)\n",
        "\n",
        "print(f\"There are {len(train_sentences)} sentences for training.\\n\")\n",
        "print(f\"There are {len(train_labels)} labels for training.\\n\")\n",
        "print(f\"There are {len(val_sentences)} sentences for validation.\\n\")\n",
        "print(f\"There are {len(val_labels)} labels for validation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZROCrT__DbNm",
        "outputId": "33f74f1a-754d-4337-b785-abcf095f5169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 1192 sentences for training.\n",
            "\n",
            "There are 1192 labels for training.\n",
            "\n",
            "There are 298 sentences for validation.\n",
            "\n",
            "There are 298 labels for validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using the Tokenizer\n",
        "\n",
        "Now it is time to tokenize the sentences of the dataset.\n",
        "\n",
        "fit_tokenizer:\n",
        "\n",
        "This function should receive the list of sentences as input and return a Tokenizer that has been fitted to those sentences."
      ],
      "metadata": {
        "id": "qWoqL5ZgMIYn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def fit_tokenizer(sentences, NUM_WORDS, OOV_TOKEN):\n",
        "    \"\"\"\n",
        "    Instantiates the Tokenizer class\n",
        "    \n",
        "    Args:\n",
        "        sentences (list): lower-cased sentences without stopwords\n",
        "    \n",
        "    Returns:\n",
        "        tokenizer (object): an instance of the Tokenizer class containing the word-index dictionary\n",
        "    \"\"\"\n",
        "    \n",
        "    # Instantiate the Tokenizer class by passing in the oov_token argument\n",
        "    tokenizer = Tokenizer(num_words=NUM_WORDS, oov_token=OOV_TOKEN)\n",
        "    # Fit on the sentences\n",
        "    tokenizer.fit_on_texts(sentences)\n",
        "    \n",
        "    return tokenizer"
      ],
      "metadata": {
        "id": "Zj380RYeMh2n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = fit_tokenizer(train_sentences, NUM_WORDS, OOV_TOKEN)\n",
        "word_index = tokenizer.word_index\n",
        "\n",
        "print(f\"Vocabulary contains {len(word_index)} words\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CQEJbKJEMTjx",
        "outputId": "c50bfef6-7a10-4431-803e-ae9f63e46390"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary contains 22647 words\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_padded_sequences(sentences, tokenizer, PADDING, MAXLEN):\n",
        "    \"\"\"\n",
        "    Generates an array of token sequences and pads them to the same length\n",
        "    \n",
        "    Args:\n",
        "        tokenizer (object): Tokenizer instance containing the word-index dictionary\n",
        "        sentences (list of string): list of sentences to tokenize and pad\n",
        "    \n",
        "    Returns:\n",
        "        padded_sequences (array of int): tokenized sentences padded to the same length\n",
        "    \"\"\"\n",
        "    \n",
        "    # Convert sentences to sequences\n",
        "    sequences = tokenizer.texts_to_sequences(sentences)\n",
        "    \n",
        "    # Pad the sequences using the post padding strategy\n",
        "    padded_sequences = pad_sequences(sequences, padding=PADDING, maxlen=MAXLEN)\n",
        "    \n",
        "    return padded_sequences"
      ],
      "metadata": {
        "id": "gOXvzCvBMYfj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_padded_seq = get_padded_sequences(train_sentences, tokenizer, PADDING, MAXLEN)\n",
        "val_padded_seq = get_padded_sequences(val_sentences, tokenizer, PADDING, MAXLEN)\n",
        "\n",
        "print(f\"Padded training sequences have shape: {train_padded_seq.shape}\\n\")\n",
        "print(f\"Padded validation sequences have shape: {val_padded_seq.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQ7nXqG9Ndts",
        "outputId": "8cf4b324-d0cc-40b7-b0b8-6f9b29b51b06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Padded training sequences have shape: (1192, 120)\n",
            "\n",
            "Padded validation sequences have shape: (298, 120)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**NOTE**: Using Keras' Tokenizer yields values that start at 1 rather than at 0. This will present a problem when training since Keras usually expects the labels to start at 0. To work around this issue we could use an extra neuron in the last layer of our model. However this approach is rather hacky and not very clear. Instead we will substract 1 from every value of the labels that the function returns. "
      ],
      "metadata": {
        "id": "okpmhCCvGU-g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "vjREWn09GuM-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_labels(labels, split_labels):\n",
        "    \"\"\"\n",
        "    Tokenizes the labels\n",
        "    \n",
        "    Args:\n",
        "        labels (list of string): labels to tokenize\n",
        "    \n",
        "    Returns:\n",
        "        label_sequences, label_word_index (list of string, dictionary): tokenized labels and the word-index\n",
        "    \"\"\"\n",
        "    # Instantiate the Tokenizer class\n",
        "    label_tokenizer = Tokenizer()\n",
        "    \n",
        "    # Fit the tokenizer to the labels\n",
        "    label_tokenizer.fit_on_texts(labels)\n",
        "    \n",
        "    # Save the word index\n",
        "    label_word_index = label_tokenizer.word_index\n",
        "    \n",
        "    # Save the sequences\n",
        "    label_sequences = label_tokenizer.texts_to_sequences(split_labels)\n",
        "\n",
        "    # Convert sequences to a numpy array.\n",
        "    label_seq_np = []\n",
        "    num_labels = len(np.unique(labels))\n",
        "    for label in label_sequences:\n",
        "      temp = [0 for _ in range(num_labels)]\n",
        "      temp[label[0] - 1] = 1\n",
        "      label_seq_np.append(temp)\n",
        "    label_seq_np = np.array(label_seq_np)\n",
        "    \n",
        "    return label_seq_np"
      ],
      "metadata": {
        "id": "31LKJfn2OTUi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_label_seq = tokenize_labels(labels, train_labels)\n",
        "val_label_seq = tokenize_labels(labels, val_labels)\n",
        "\n",
        "print(f\"First 5 labels of the training set should look like this:\\n{train_label_seq[:5]}\\n\")\n",
        "print(f\"First 5 labels of the validation set should look like this:\\n{val_label_seq[:5]}\\n\")\n",
        "print(f\"Tokenized labels of the training set have shape: {train_label_seq.shape}\\n\")\n",
        "print(f\"Tokenized labels of the validation set have shape: {val_label_seq.shape}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gpeIBth9PmAV",
        "outputId": "6505563c-3e0e-4c85-c68c-4ca34ac57a73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First 5 labels of the training set should look like this:\n",
            "[[0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]\n",
            " [0 1 0 0 0]]\n",
            "\n",
            "First 5 labels of the validation set should look like this:\n",
            "[[0 0 0 1 0]\n",
            " [0 0 0 1 0]\n",
            " [0 0 1 0 0]\n",
            " [0 1 0 0 0]\n",
            " [0 0 0 0 1]]\n",
            "\n",
            "Tokenized labels of the training set have shape: (1192, 5)\n",
            "\n",
            "Tokenized labels of the validation set have shape: (298, 5)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Selecting the model for text classification\n",
        "\n",
        "Now that the data is ready to be fed a Neural Network it is time for us to define the model that will classify each text as being part of a certain category.\n",
        "\n",
        "Complete the create_model below.\n",
        "\n",
        "A couple of things to keep in mind:\n",
        "\n",
        "* Notice that this function has three parameters, all of which are meant to be passed to an Embedding layer, which is what we will probably use as a first layer for your model.\n",
        "\n",
        "* The last layer should be a Dense layer with 5 units (since there are 5 categories) with a softmax activation.\n",
        "\n",
        "* You should also compile your model using an appropiate loss function and optimizer.\n",
        "\n",
        "* You can use any architecture you want but keep in mind that this problem doesn't need many layers to be solved successfully. You don't need any layers beside Embedding, GlobalAveragePooling1D and Dense layers but feel free to try out different architectures.\n",
        "\n",
        "* To pass this graded function your model should reach at least a 95% training accuracy and a 90% validation accuracy in under 30 epochs."
      ],
      "metadata": {
        "id": "6I6P3e2eG8JL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "rMK4HBJKHldY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(num_words, embedding_dim, maxlen):\n",
        "    \"\"\"\n",
        "    Creates a text classifier model\n",
        "    \n",
        "    Args:\n",
        "        num_words (int): size of the vocabulary for the Embedding layer input\n",
        "        embedding_dim (int): dimensionality of the Embedding layer output\n",
        "        maxlen (int): length of the input sequences\n",
        "    \n",
        "    Returns:\n",
        "        model (tf.keras Model): the text classifier model\n",
        "    \"\"\"\n",
        "    \n",
        "    tf.random.set_seed(23)\n",
        "    \n",
        "    model = tf.keras.Sequential([ \n",
        "        tf.keras.layers.Embedding(num_words, embedding_dim, input_length=maxlen),\n",
        "        tf.keras.layers.GlobalAveragePooling1D(),\n",
        "        tf.keras.layers.Dense(32, activation='relu'),\n",
        "        tf.keras.layers.Dense(5, activation='softmax')\n",
        "    ])\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy',\n",
        "                  optimizer='adam',\n",
        "                  metrics=['accuracy']) \n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "Lp3Hv7U-HM2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = create_model(NUM_WORDS, EMBEDDING_DIM, MAXLEN)\n",
        "\n",
        "history = model.fit(train_padded_seq, train_label_seq, epochs=30, validation_data=(val_padded_seq, val_label_seq))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DpfkbS_uIcdZ",
        "outputId": "40cd0c83-2e3a-4fd1-a2ad-e6a1ace033e4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "38/38 [==============================] - 1s 8ms/step - loss: 1.6034 - accuracy: 0.2366 - val_loss: 1.5999 - val_accuracy: 0.2114\n",
            "Epoch 2/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.5824 - accuracy: 0.4044 - val_loss: 1.5774 - val_accuracy: 0.3557\n",
            "Epoch 3/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.5400 - accuracy: 0.4237 - val_loss: 1.5282 - val_accuracy: 0.3926\n",
            "Epoch 4/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.4572 - accuracy: 0.4497 - val_loss: 1.4376 - val_accuracy: 0.4262\n",
            "Epoch 5/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.3310 - accuracy: 0.4664 - val_loss: 1.3152 - val_accuracy: 0.4497\n",
            "Epoch 6/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.1853 - accuracy: 0.5101 - val_loss: 1.1835 - val_accuracy: 0.5268\n",
            "Epoch 7/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 1.0455 - accuracy: 0.6342 - val_loss: 1.0604 - val_accuracy: 0.6208\n",
            "Epoch 8/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.9188 - accuracy: 0.7181 - val_loss: 0.9443 - val_accuracy: 0.7047\n",
            "Epoch 9/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.7994 - accuracy: 0.7953 - val_loss: 0.8281 - val_accuracy: 0.8087\n",
            "Epoch 10/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.6865 - accuracy: 0.8674 - val_loss: 0.7201 - val_accuracy: 0.8859\n",
            "Epoch 11/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.5809 - accuracy: 0.9220 - val_loss: 0.6269 - val_accuracy: 0.9060\n",
            "Epoch 12/30\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.4933 - accuracy: 0.9404 - val_loss: 0.5427 - val_accuracy: 0.9195\n",
            "Epoch 13/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.4188 - accuracy: 0.9522 - val_loss: 0.4745 - val_accuracy: 0.9463\n",
            "Epoch 14/30\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.3554 - accuracy: 0.9631 - val_loss: 0.4166 - val_accuracy: 0.9463\n",
            "Epoch 15/30\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.3029 - accuracy: 0.9673 - val_loss: 0.3699 - val_accuracy: 0.9530\n",
            "Epoch 16/30\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.2588 - accuracy: 0.9740 - val_loss: 0.3299 - val_accuracy: 0.9497\n",
            "Epoch 17/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.2222 - accuracy: 0.9723 - val_loss: 0.2999 - val_accuracy: 0.9530\n",
            "Epoch 18/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.1919 - accuracy: 0.9782 - val_loss: 0.2735 - val_accuracy: 0.9530\n",
            "Epoch 19/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.1676 - accuracy: 0.9815 - val_loss: 0.2548 - val_accuracy: 0.9530\n",
            "Epoch 20/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.1474 - accuracy: 0.9841 - val_loss: 0.2388 - val_accuracy: 0.9530\n",
            "Epoch 21/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.1303 - accuracy: 0.9874 - val_loss: 0.2302 - val_accuracy: 0.9463\n",
            "Epoch 22/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.1153 - accuracy: 0.9874 - val_loss: 0.2155 - val_accuracy: 0.9530\n",
            "Epoch 23/30\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.1032 - accuracy: 0.9908 - val_loss: 0.2070 - val_accuracy: 0.9530\n",
            "Epoch 24/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0928 - accuracy: 0.9916 - val_loss: 0.1989 - val_accuracy: 0.9564\n",
            "Epoch 25/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0834 - accuracy: 0.9916 - val_loss: 0.1944 - val_accuracy: 0.9530\n",
            "Epoch 26/30\n",
            "38/38 [==============================] - 0s 2ms/step - loss: 0.0753 - accuracy: 0.9941 - val_loss: 0.1872 - val_accuracy: 0.9564\n",
            "Epoch 27/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0679 - accuracy: 0.9933 - val_loss: 0.1853 - val_accuracy: 0.9530\n",
            "Epoch 28/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0623 - accuracy: 0.9950 - val_loss: 0.1791 - val_accuracy: 0.9564\n",
            "Epoch 29/30\n",
            "38/38 [==============================] - 0s 4ms/step - loss: 0.0561 - accuracy: 0.9958 - val_loss: 0.1766 - val_accuracy: 0.9631\n",
            "Epoch 30/30\n",
            "38/38 [==============================] - 0s 3ms/step - loss: 0.0510 - accuracy: 0.9966 - val_loss: 0.1721 - val_accuracy: 0.9631\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "BA7bw_qdCp4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_graphs(history, metric):\n",
        "    plt.plot(history.history[metric])\n",
        "    plt.plot(history.history[f'val_{metric}'])\n",
        "    plt.xlabel(\"Epochs\")\n",
        "    plt.ylabel(metric)\n",
        "    plt.legend([metric, f'val_{metric}'])\n",
        "    plt.show()\n",
        "    \n",
        "plot_graphs(history, \"accuracy\")\n",
        "plot_graphs(history, \"loss\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        },
        "id": "d8jQzOGjBeUh",
        "outputId": "90903863-344c-4b20-d158-49f72ed4fdd3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Visualizing 3D Vectors\n",
        "We can visualize the vectors associated with each word in the training set in a 3D space.\n"
      ],
      "metadata": {
        "id": "jNuVhKDXDK0Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Reverse word index\n",
        "reverse_word_index = dict([(value, key) for (key, value) in word_index.items()])\n",
        "\n",
        "# Save the embedding layer\n",
        "e = model.layers[0]\n",
        "\n",
        "# Save the weights of the embedding layer\n",
        "weights = e.get_weights()[0]\n",
        "print(f\"Weights of embedding layer have shape: {weights.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH5B-i96DTed",
        "outputId": "889c5867-bbcb-4cc6-d0f8-8b9f9e883156"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weights of embedding layer have shape: (1000, 16)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate the vecs.tsv and meta.tsv files that we can upload to the embedding projector by visiting Tensorflow's Embedding Projector.\n",
        "\n"
      ],
      "metadata": {
        "id": "7LNu0zSnDmok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import io"
      ],
      "metadata": {
        "id": "dnF_UqvXDr3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate files for embedding visualization\n",
        "out_v = io.open('vecs.tsv', 'w', encoding='utf-8')\n",
        "out_m = io.open('meta.tsv', 'w', encoding='utf-8')\n",
        "for word_num in range(1, NUM_WORDS):\n",
        "    word = reverse_word_index[word_num]\n",
        "    embeddings = weights[word_num]\n",
        "    out_m.write(word + \"\\n\")\n",
        "    out_v.write('\\t'.join([str(x) for x in embeddings]) + \"\\n\")\n",
        "out_v.close()\n",
        "out_m.close()"
      ],
      "metadata": {
        "id": "_1Arw6zwDdVy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import files utilities in Colab\n",
        "try:\n",
        "  from google.colab import files\n",
        "except ImportError:\n",
        "  pass\n",
        "\n",
        "# Download the files\n",
        "else:\n",
        "  files.download('vecs.tsv')\n",
        "  files.download('meta.tsv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "-Dy6ZZPEEWUM",
        "outputId": "b98a8abc-8889-49ae-9672-f4f93e6ff28d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_8640c5b3-e57b-4da2-a219-d6bcbeff566a\", \"vecs.tsv\", 182716)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_bc77a860-5927-48b1-a5c5-781fc5ae9163\", \"meta.tsv\", 6558)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.unique(labels)"
      ],
      "metadata": {
        "id": "sApRooDxFeu3",
        "outputId": "5630f1ff-f8b8-4c33-f4bf-07a1e50cd4a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['business', 'entertainment', 'politics', 'sport', 'tech'],\n",
              "      dtype='<U13')"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can visualize the final weights of the embeddings using the Tensorflow Embedding Projector at https://projector.tensorflow.org/."
      ],
      "metadata": {
        "id": "JNslTd5LlfrH"
      }
    }
  ]
}